0 前言
=====
    写笔记之前，先介绍一下自己目前的水平。做为一个业余编程爱好者，之前买了不少python和数据分析的入门书籍，认真看完了其中几本，
    在udacity上拿到了数据分析(入门)的纳米学位。  另外机器学习、深度学习的书也买有几本，在各类网站也买了不少视频课和文字专栏课，但是基本都没有看。
    目前已掌握python基础，了解数据分析相关的numpy、pandas、matplotlib库的基本用法。

    最开始关注人工智能，也是从alpha go战胜李世石开始。后来看过udacity的一些直播分享和免费的机器学习和pytorch入门视频课，
    知道了机器学习和深度学习的概念和区别。也看了机器学习、深度学习的学习路线图，知道了一些术语。各种博客或者IT培训基本上一说机器学习，都说要有数学基础，微积分、线性代数、概率论等等。
    然后就是具体的各类算法，分类、回归、神经网络。作为高数挂过科的人，我一直觉得这些都很难懂，但只按着别人的例子敲代码，做个调包侠，又一点也不好玩，所以我一直没有深入学机器学习。

    我个人感觉，这次的天池机器学习课程，基本上和上次的python课程一样，适合经验丰富、学习能力强的从业者，不适合编程小白。
    要读懂代码，需要自己搜索的东西太多了。如果能看懂的话，基本上都是已经入门的人了。我自己感觉算是机器学习方面的小白和入门之间。
    借着这次机会，正好把之前买的书和专栏好好看看。以下是从各种书和专栏里摘录换成自己的语言总结的。

1 基础概念
=====
机器学习的概念和应用： 这部分网上比较多，也好理解。这里借用一个专栏上的比喻。
机器学习相当于小学生做算术题的过程。做算术题分为做题，校验，归纳总结三步，对应机器学习的模型，策略、算法。
模型就是确定一个函数y=f($Omega$,x),x为输入，也叫特征向量，y为输出，也叫预测值。$Omega$代表各种参数。
机器学习的目的，就是不断调整w的值，使得预测效果最好。
校验就是把模型的输出和真实值对照，判断模型的好坏，一般用损失函数来衡量。
归纳就是求极值，找出损失函数最小所对应的$w$值。
 
    机器学习的分类：有分两种的，也有分三种或四种的，比如监督学习、非监督学习、半监督学习、强化学习等等。
    其中最常见的是监督学习和非监督学习。监督学习与非监督学习最大的差别，在于数据是否有标注。
    数据如果已有标注（一般是人工赋予标签），一般用监督学习，常见的算法有分类算法和回归算法。
    数据没有标注，一般只能用非监督学习，常见的算法有聚类算法和降维算法。
    
    最常见的监督学习可以分为回归问题和分类问题两类。二者最大区别在于，输出变量的类型不同。
    分类问题，输出为有限个离散变量、布尔值或定类变量。相当于上面举的小学生做算术题的场景里，做的是选择题。
    回归问题，输出为连续变量，一般为实数，也就是一个确切值。相当于上面举的小学生做算术题的场景里，做的是填空题。
    
    再举一个例子，比如根据各类气象数据，判断明天是否会下雨，是分类问题，因为结果只有“会下雨”、“不会下雨”两种。
    如果根据各类气象数据，判断明天的降雨量是多少，这就是回归问题，因为结果是连续的数据。

    线性模型中最小二乘回归（ordinary least squares,OLS）、岭回归(L2正则化)、拉索回归(L1正则化)、贝叶斯回归等是用于解决回归问题。而感知机、逻辑回归被用于解决分类问题。

 2 scikit-learn库的一般使用方法
 =======
   使用scikit-learn的一般步骤： 
   1、调用某个机器学习方法法所对应的模型model，设置模型参数。   
   2、用该模型的fit()方法训练模型,通过.coef_和.intercept_查看斜率和截距。   
   注：fit方法返回的是修改侯的模型对象本身。coef_和intercept_以下划线结尾，是因为这连个属性是从训练数据中得出的值，而不是用户设置的参数。    
   3、用该模型的predict()方法或predict_proba()方法用于预测。  
   4、用model.score(data_X, data_y) 方法评估模型。  
      对于分类问题，该方法返回的是精度(accuracy),即预测正确的样本数占样本总数的比例。  
      对于回归问题，该方法返回的是 R^2分数，R^2分数也叫决定系数，是回归模型预测的优度度量，位于0到1之间。  
      R^2等于1对应完美预测，R^2等于0对应常数模型，即总是预测训练集响应(y_train)的平均值。    
      评估回归模型也可以用军方误差或平均绝对误差。   
   
   其他的一些属性和方法：  
   model.get_params()取出之前定义的参数。


3 加载数据集和查看数据集
=========
```
from sklearn import datasets
#load_boston()返回的是一个Bunch对象，类似于字典，但是可以用点操作符来访问对象的值
loaded_data = datasets.load_boston()
data_X = loaded_data.data
data_y = loaded_data.target
```

 
 4 切分数据集
 =========
    划分训练集和测试集,一般70%为训练集，30%为测试集,默认为75%为训练集，25%为测试集。
```
from sklearn.model_selection import train_test_split
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0)
```


